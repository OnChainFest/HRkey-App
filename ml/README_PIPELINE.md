# HRScore ML Pipeline - Gu√≠a de Uso Local

**Versi√≥n:** 1.0
**Fecha:** 2025-12-23
**Autor:** HRKey ML Team

---

## üìã √çndice

1. [Descripci√≥n General](#descripci√≥n-general)
2. [Requisitos](#requisitos)
3. [Configuraci√≥n Inicial](#configuraci√≥n-inicial)
4. [Pipeline Completo](#pipeline-completo)
5. [Uso Avanzado](#uso-avanzado)
6. [Artifacts Generados](#artifacts-generados)
7. [Troubleshooting](#troubleshooting)

---

## üìñ Descripci√≥n General

Este pipeline entrena modelos ML para predecir **HRScore** (0-100) basado en observaciones reales de KPIs.

### Componentes:

1. **`DATASET_SPEC.md`** - Especificaci√≥n t√©cnica del dataset
2. **`extract_dataset.py`** - Extracci√≥n de datos desde Supabase
3. **`train_hrscore.py`** - Entrenamiento de modelos ML
4. **`artifacts/`** - Modelos versionados + m√©tricas + manifests

### Flujo:

```
Supabase DB (kpi_observations)
        ‚Üì
extract_dataset.py ‚Üí CSV dataset
        ‚Üì
train_hrscore.py ‚Üí Trained models
        ‚Üì
artifacts/ (model.pkl + manifest.json + metrics.json)
```

---

## üîß Requisitos

### Python 3.8+

Instala las dependencias:

```bash
cd /home/user/HRkey-App

# Opci√≥n 1: pip
pip install -r ml/requirements.txt

# Opci√≥n 2: crear virtualenv (recomendado)
python3 -m venv venv
source venv/bin/activate
pip install -r ml/requirements.txt
```

### Dependencias principales:

- `pandas` - Manipulaci√≥n de datos
- `numpy` - C√°lculos num√©ricos
- `scikit-learn` - Modelos ML
- `xgboost` (opcional) - Modelo XGBoost
- `supabase-py` (opcional) - Cliente de Supabase
- `python-dotenv` - Variables de entorno
- `joblib` - Serializaci√≥n de modelos

### Credenciales de Supabase

Crea/actualiza `.env` en la ra√≠z del proyecto:

```bash
# .env
SUPABASE_URL=https://wrervcydgdrlcndtjboy.supabase.co
SUPABASE_SERVICE_KEY=eyJhbGc...  # Service key (no anon key!)
# O usa SUPABASE_ANON_KEY si no tienes service key
```

**IMPORTANTE:** Nunca comitees el `.env` con credenciales reales.

---

## ‚öôÔ∏è Configuraci√≥n Inicial

### 1. Verificar datos en Supabase

Aseg√∫rate de tener observaciones de KPIs en la tabla `kpi_observations`:

```bash
# Contar observaciones (requiere psql o Supabase dashboard)
# O usa el script de verificaci√≥n:
python -c "
from ml.extract_dataset import get_supabase_client, execute_query
client = get_supabase_client()
df = execute_query(client, 'kpi_observations', 'id')
print(f'Total observaciones: {len(df)}')
"
```

M√≠nimo recomendado:
- **50+ observaciones** por KPI
- **3+ observadores** diferentes por subject
- **3+ KPIs evaluados** por subject

### 2. Crear directorios (se crean autom√°ticamente)

```bash
mkdir -p ml/data ml/models ml/output ml/artifacts
```

---

## üöÄ Pipeline Completo

### PASO 1: Extraer Dataset

Extrae datos de Supabase y construye el dataset ML:

```bash
cd /home/user/HRkey-App

# Extracci√≥n b√°sica (usa defaults)
python ml/extract_dataset.py

# Con filtros personalizados
python ml/extract_dataset.py \
  --min-observations 3 \
  --min-observers 2 \
  --min-kpis-evaluated 3

# Especificar output
python ml/extract_dataset.py \
  --output ml/data/dataset_custom.csv
```

**Output esperado:**
```
ml/data/hrscore_dataset_20251223_120000.csv       # Dataset
ml/data/hrscore_dataset_20251223_120000.json      # Metadata
```

**Par√°metros:**

| Flag | Default | Descripci√≥n |
|------|---------|-------------|
| `--min-observations` | 3 | M√≠nimo de observaciones por KPI |
| `--min-observers` | 2 | M√≠nimo de observadores √∫nicos |
| `--min-kpis-evaluated` | 3 | M√≠nimo de KPIs evaluados |
| `--min-verified-pct` | None | M√≠nimo % verificadas (0.0-1.0) |
| `--min-observation-span-days` | None | M√≠nimo d√≠as de observaci√≥n |

**Verificar dataset:**

```bash
# Ver primeras filas
head -20 ml/data/hrscore_dataset_*.csv

# Contar filas
wc -l ml/data/hrscore_dataset_*.csv

# Ver metadata
cat ml/data/hrscore_dataset_*.json | jq .
```

---

### PASO 2: Entrenar Modelos

Entrena modelos ML usando el dataset extra√≠do:

```bash
# Entrenamiento b√°sico (usa dataset m√°s reciente)
python ml/train_hrscore.py

# Especificar dataset
python ml/train_hrscore.py \
  --dataset ml/data/hrscore_dataset_20251223_120000.csv

# Entrenar solo modelos espec√≠ficos
python ml/train_hrscore.py \
  --models ridge random_forest

# Ajustar par√°metros
python ml/train_hrscore.py \
  --test-size 0.3 \
  --cv-folds 10 \
  --random-state 42

# Versi√≥n custom
python ml/train_hrscore.py \
  --version v1.0-prod
```

**Output esperado:**

```
ml/artifacts/ridge_20251223_120000/
  ‚îú‚îÄ‚îÄ model.pkl                 # Pipeline completo (preprocessing + modelo)
  ‚îú‚îÄ‚îÄ manifest.json             # Metadata completa
  ‚îú‚îÄ‚îÄ metrics.json              # M√©tricas de evaluaci√≥n
  ‚îú‚îÄ‚îÄ feature_importance.csv    # Importancia de features
  ‚îî‚îÄ‚îÄ README.md                 # Documentaci√≥n del artifact

ml/artifacts/random_forest_20251223_120000/
  ‚îî‚îÄ‚îÄ ...

ml/artifacts/latest_best -> ridge_20251223_120000/  # Symlink al mejor
```

**Par√°metros:**

| Flag | Default | Descripci√≥n |
|------|---------|-------------|
| `--dataset` | M√°s reciente | Path del dataset CSV |
| `--models` | Todos | Modelos a entrenar: `ridge`, `linear`, `random_forest`, `xgboost` |
| `--test-size` | 0.2 | Proporci√≥n de test set (0.0-1.0) |
| `--cv-folds` | 5 | N√∫mero de folds para cross-validation |
| `--random-state` | 42 | Semilla para reproducibilidad |
| `--version` | Timestamp | Versi√≥n custom para artifacts |

**Modelos disponibles:**

| Modelo | Descripci√≥n | Pros | Contras |
|--------|-------------|------|---------|
| `ridge` | Regresi√≥n Ridge (L2 regularizaci√≥n) | Simple, interpretable, r√°pido | Asume linealidad |
| `linear` | Regresi√≥n lineal b√°sica | Muy simple, baseline | Sin regularizaci√≥n |
| `random_forest` | Random Forest Regressor | No lineal, robusto | Menos interpretable |
| `xgboost` | XGBoost Regressor | SOTA performance | Requiere m√°s datos, lento |

---

### PASO 3: Evaluar Resultados

#### Ver m√©tricas del mejor modelo:

```bash
cat ml/artifacts/latest_best/metrics.json | jq .
```

**Ejemplo de output:**

```json
{
  "test": {
    "mae": 5.23,
    "rmse": 7.45,
    "r2": 0.78
  },
  "train": {
    "mae": 3.21,
    "rmse": 4.56,
    "r2": 0.89
  },
  "cv": {
    "r2_mean": 0.76,
    "r2_std": 0.05,
    "r2_scores": [0.72, 0.78, 0.75, 0.79, 0.76]
  }
}
```

**Interpretaci√≥n de m√©tricas:**

- **R¬≤ (0-1):** Proporci√≥n de varianza explicada. >0.7 = bueno, >0.8 = excelente
- **MAE:** Error absoluto medio en puntos de HRScore. <5 = bueno
- **RMSE:** Penaliza errores grandes. <8 = bueno
- **CV R¬≤ mean:** R¬≤ promedio en cross-validation (m√°s confiable que test R¬≤)
- **Overfitting gap:** `train R¬≤ - test R¬≤`. <0.1 = bueno, >0.2 = overfitting

#### Ver feature importance:

```bash
head -10 ml/artifacts/latest_best/feature_importance.csv
```

**Ejemplo:**

```csv
feature,importance
code_quality_avg_rating,4.82
test_coverage_avg_rating,3.91
deployment_frequency_avg_rating,3.42
total_observations,2.15
...
```

#### Ver manifest completo:

```bash
cat ml/artifacts/latest_best/manifest.json | jq .
```

Incluye:
- Metadata del modelo (tipo, params, versi√≥n sklearn)
- Info del dataset usado
- Features y su importancia
- M√©tricas de performance
- Instrucciones de reproducibilidad

---

## üî¨ Uso Avanzado

### Cargar y usar modelo para predicci√≥n

```python
import joblib
import pandas as pd

# Cargar modelo
model = joblib.load('ml/artifacts/latest_best/model.pkl')

# Preparar datos (debe tener las mismas features)
X_new = pd.DataFrame({
    'code_quality_avg_rating': [4.5],
    'code_quality_n_obs': [10],
    'code_quality_n_observers': [5],
    'code_quality_verified_pct': [0.8],
    'test_coverage_avg_rating': [4.2],
    'test_coverage_n_obs': [8],
    'test_coverage_n_observers': [4],
    'test_coverage_verified_pct': [0.75],
    # ... resto de features (ver manifest.json)
})

# Predecir
predictions = model.predict(X_new)
print(f'Predicted HRScore: {predictions[0]:.2f}')
```

### Exportar modelo para Node.js (como actual)

El modelo actual en `backend/hrkeyScoreService.js` usa un JSON config. Para exportarlo:

```python
import joblib
import json
import numpy as np

# Cargar modelo
pipeline = joblib.load('ml/artifacts/latest_best/model.pkl')
regressor = pipeline.named_steps['regressor']

# Extraer coeficientes (solo para modelos lineales)
if hasattr(regressor, 'coef_'):
    # Cargar metadata de features
    with open('ml/artifacts/latest_best/manifest.json', 'r') as f:
        manifest = json.load(f)

    feature_names = manifest['features']['names']

    # Construir config
    config = {
        'model_type': type(regressor).__name__,
        'intercept': float(regressor.intercept_),
        'coefficients': dict(zip(feature_names, regressor.coef_)),
        'features': feature_names,
        'target_stats': {
            # Calcular desde datos de entrenamiento
            'min': 0.0,
            'max': 100.0,
            'mean': 70.0,
            'std': 15.0
        }
    }

    # Guardar
    with open('ml/output/hrkey_model_config_global.json', 'w') as f:
        json.dump(config, f, indent=2)
```

### Re-entrenar con m√°s datos

Si agregaste m√°s observaciones a Supabase:

```bash
# 1. Extraer nuevo dataset
python ml/extract_dataset.py

# 2. Re-entrenar
python ml/train_hrscore.py --version v1.1

# 3. Comparar con versi√≥n anterior
diff ml/artifacts/ridge_v1.0/metrics.json ml/artifacts/ridge_v1.1/metrics.json
```

### Entrenar modelos por rol

Si tienes suficientes datos, entrena modelos espec√≠ficos por rol:

```bash
# Modificar extract_dataset.py para filtrar por role_id
# O procesar el CSV con pandas:

python -c "
import pandas as pd

df = pd.read_csv('ml/data/hrscore_dataset_latest.csv')

# Obtener roles √∫nicos
roles = df['role_id'].unique()

for role_id in roles:
    df_role = df[df['role_id'] == role_id]
    if len(df_role) >= 50:  # M√≠nimo 50 muestras
        output = f'ml/data/dataset_role_{role_id}.csv'
        df_role.to_csv(output, index=False)
        print(f'Saved {output}: {len(df_role)} samples')
"

# Entrenar por rol
for dataset in ml/data/dataset_role_*.csv; do
    python ml/train_hrscore.py --dataset $dataset --version role_specific
done
```

---

## üì¶ Artifacts Generados

### Estructura de directorios:

```
ml/
‚îú‚îÄ‚îÄ DATASET_SPEC.md               # Especificaci√≥n del dataset
‚îú‚îÄ‚îÄ README_PIPELINE.md            # Esta gu√≠a
‚îú‚îÄ‚îÄ extract_dataset.py            # Script de extracci√≥n
‚îú‚îÄ‚îÄ train_hrscore.py              # Script de entrenamiento
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias Python
‚îÇ
‚îú‚îÄ‚îÄ data/                         # Datasets extra√≠dos
‚îÇ   ‚îú‚îÄ‚îÄ hrscore_dataset_20251223_120000.csv
‚îÇ   ‚îî‚îÄ‚îÄ hrscore_dataset_20251223_120000.json
‚îÇ
‚îú‚îÄ‚îÄ artifacts/                    # Modelos versionados
‚îÇ   ‚îú‚îÄ‚îÄ ridge_20251223_120000/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manifest.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_20251223_120000/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ latest_best -> ridge_20251223_120000/  # Symlink
‚îÇ
‚îú‚îÄ‚îÄ output/                       # Outputs legacy (backward compat)
‚îÇ   ‚îú‚îÄ‚îÄ hrkey_model_config_global.json
‚îÇ   ‚îî‚îÄ‚îÄ baseline_metrics_global.json
‚îÇ
‚îî‚îÄ‚îÄ models/                       # Modelos legacy
    ‚îî‚îÄ‚îÄ ridge_global.pkl
```

### Archivos importantes:

| Archivo | Descripci√≥n |
|---------|-------------|
| `artifacts/{model}_{version}/model.pkl` | Pipeline completo (preprocessing + modelo) |
| `artifacts/{model}_{version}/manifest.json` | Metadata completa (features, params, performance) |
| `artifacts/{model}_{version}/metrics.json` | M√©tricas de evaluaci√≥n |
| `artifacts/{model}_{version}/feature_importance.csv` | Importancia de cada feature |
| `artifacts/latest_best/` | Symlink al mejor modelo |

### Manifest schema:

```json
{
  "model": {
    "name": "ridge",
    "version": "20251223_120000",
    "type": "Ridge",
    "params": {...},
    "sklearn_version": "1.3.0"
  },
  "training": {
    "date": "2025-12-23T12:00:00",
    "dataset": {...},
    "params": {...},
    "random_state": 42
  },
  "features": {
    "names": ["code_quality_avg_rating", ...],
    "count": 29,
    "importance": {"code_quality_avg_rating": 4.82, ...}
  },
  "performance": {
    "test": {"mae": 5.23, "rmse": 7.45, "r2": 0.78},
    "train": {...},
    "cv": {...}
  },
  "target": {
    "name": "target_score",
    "description": "HRScore (0-100)",
    "range": [0, 100]
  },
  "reproducibility": {
    "instructions": "Ver ml/README_PIPELINE.md",
    "command": "python ml/train_hrscore.py --dataset ..."
  }
}
```

---

## üêõ Troubleshooting

### Error: "No se encontraron datos en kpi_observations"

**Causa:** Tabla vac√≠a o credenciales incorrectas.

**Soluci√≥n:**
```bash
# Verificar credenciales
echo $SUPABASE_URL
echo $SUPABASE_SERVICE_KEY

# Insertar observaciones de prueba
curl -X POST http://localhost:3001/api/kpi-observations \
  -H "Content-Type: application/json" \
  -d '{
    "subject_wallet": "0x123...",
    "observer_wallet": "0x456...",
    "kpi_name": "code_quality",
    "rating_value": 4.5,
    "role_id": "..."
  }'
```

### Error: "Dataset demasiado peque√±o"

**Causa:** No hay suficientes observaciones despu√©s de filtros.

**Soluci√≥n:**
```bash
# Reducir thresholds
python ml/extract_dataset.py \
  --min-observations 2 \
  --min-observers 1 \
  --min-kpis-evaluated 2

# O insertar m√°s datos
```

### Error: "target_score NULL"

**Causa:** No hay HRScores calculados en la tabla `hrkey_scores`.

**Soluci√≥n:**
```bash
# Calcular HRScores para todos los usuarios
curl -X POST http://localhost:3001/api/hrscore/calculate \
  -H "Authorization: Bearer $ADMIN_TOKEN"

# O entrenar sin target (unsupervised)
# Requiere modificar train_hrscore.py
```

### Error: "XGBoost no disponible"

**Causa:** Librer√≠a xgboost no instalada.

**Soluci√≥n:**
```bash
# Instalar XGBoost
pip install xgboost

# O entrenar sin XGBoost
python ml/train_hrscore.py --models ridge random_forest
```

### Performance pobre (R¬≤ < 0.5)

**Causas posibles:**
1. Pocos datos de entrenamiento
2. Features no informativas
3. Target ruidoso

**Soluciones:**
```bash
# 1. Revisar distribuci√≥n de datos
python -c "
import pandas as pd
df = pd.read_csv('ml/data/hrscore_dataset_latest.csv')
print(df.describe())
print(df['target_score'].hist())
"

# 2. Revisar correlaciones
python -c "
import pandas as pd
df = pd.read_csv('ml/data/hrscore_dataset_latest.csv')
kpi_cols = [c for c in df.columns if '_avg_rating' in c]
print(df[kpi_cols + ['target_score']].corr()['target_score'].sort_values())
"

# 3. Aumentar datos o mejorar features
```

### Error: "supabase-py no disponible, usando requests"

**No es error:** El script funciona con `requests` como fallback.

**Para instalar supabase-py (opcional):**
```bash
pip install supabase
```

---

## üìù Notas Finales

### ‚úÖ Checklist de validaci√≥n:

Antes de usar el modelo en producci√≥n:

- [ ] Dataset tiene >= 100 filas
- [ ] Test R¬≤ >= 0.7
- [ ] CV R¬≤ std < 0.1 (modelo estable)
- [ ] Overfitting gap < 0.15
- [ ] Features tienen sentido (ver feature importance)
- [ ] Probado en datos nuevos (no en train/test)

### üîÑ Versionado de modelos:

Usa versiones sem√°nticas para cambios importantes:

```bash
# v1.0 - Baseline
python ml/train_hrscore.py --version v1.0

# v1.1 - M√°s datos
python ml/train_hrscore.py --version v1.1

# v2.0 - Nuevas features
python ml/train_hrscore.py --version v2.0
```

### üö´ Restricciones (seg√∫n requisitos):

- ‚ùå **NO refactors grandes:** Scripts usan estructura existente
- ‚ùå **NO tocar auth middleware:** No se modifica autenticaci√≥n
- ‚ùå **NO cambiar schema:** Se usan tablas existentes sin migrations
- ‚úÖ **Solo comandos locales:** Todo se ejecuta en local, sin push a Git

### üéØ Pr√≥ximos pasos sugeridos:

1. **Implementar A/B testing:** Comparar modelo nuevo vs actual en producci√≥n
2. **Monitoreo de drift:** Detectar cuando datos cambian y re-entrenar
3. **Feature engineering:** Agregar features derivadas (interacciones, z-scores)
4. **Ensemble models:** Combinar predicciones de m√∫ltiples modelos
5. **Interpretabilidad:** SHAP values para explicar predicciones

---

## üìû Soporte

Para preguntas o problemas:

1. Revisar esta gu√≠a completa
2. Verificar logs de ejecuci√≥n
3. Revisar `DATASET_SPEC.md` para detalles t√©cnicos
4. Abrir issue en el repositorio (si aplicable)

---

**√öltima actualizaci√≥n:** 2025-12-23
**Versi√≥n del pipeline:** 1.0
