#!/usr/bin/env python3
"""
HRKey - Export Model Configuration to JSON
===========================================

Este script exporta un modelo entrenado (Ridge regression) a un archivo JSON
con toda la configuraci√≥n necesaria para realizar inferencia desde el backend
Node.js sin necesidad de ejecutar Python.

Exporta:
- Coeficientes del modelo
- Intercept
- Lista de features (KPIs) en orden
- Estad√≠sticas del target (min, max, mean, std)
- M√©tricas de entrenamiento

Autor: HRKey Data Team
Fecha: 2025-11-22

Uso:
    python ml/export_hrkey_model_config.py
    python ml/export_hrkey_model_config.py --model_path ml/models/ridge_global.pkl
    python ml/export_hrkey_model_config.py --role_id <UUID>
"""

import os
import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

import joblib
import numpy as np
import pandas as pd
from dotenv import load_dotenv

# Importar funciones del script de entrenamiento
# (asumiendo que est√°n en el mismo directorio)
try:
    from baseline_predictive_model import load_data_from_supabase, build_ml_dataset
except ImportError:
    print("‚ö†Ô∏è  No se pudo importar baseline_predictive_model.py")
    print("   Aseg√∫rate de que est√° en el mismo directorio.")
    # Definir versiones simplificadas si es necesario
    load_data_from_supabase = None
    build_ml_dataset = None

# ============================================================================
# CONFIGURACI√ìN
# ============================================================================

load_dotenv()

MODELS_DIR = Path(__file__).parent / 'models'
OUTPUT_DIR = Path(__file__).parent / 'output'

# ============================================================================
# 1. CARGA Y EXTRACCI√ìN DE CONFIGURACI√ìN DEL MODELO
# ============================================================================

def load_model_and_extract_config(
    model_path: Path,
    role_id: Optional[str] = None
) -> Dict:
    """
    Carga un modelo entrenado y extrae su configuraci√≥n completa.

    Args:
        model_path: Path al archivo .pkl del modelo
        role_id: ID del rol (None = global)

    Returns:
        Dict: Configuraci√≥n completa del modelo en formato JSON-serializable

    Raises:
        FileNotFoundError: Si el modelo no existe
        ValueError: Si el modelo no tiene la estructura esperada
    """
    print("="*80)
    print("EXPORTANDO CONFIGURACI√ìN DEL MODELO HRKEY")
    print("="*80)
    print(f"Modelo: {model_path}")
    print(f"Role ID: {role_id if role_id else 'Global'}")
    print("")

    # ========================================
    # 1. Cargar el modelo
    # ========================================
    if not model_path.exists():
        raise FileNotFoundError(
            f"Modelo no encontrado: {model_path}\n"
            "Ejecuta primero: python ml/baseline_predictive_model.py"
        )

    print("üì¶ Cargando modelo...")
    pipeline = joblib.load(model_path)
    print(f"   ‚úÖ Modelo cargado: {type(pipeline)}")

    # Validar que sea un pipeline con regressor
    if not hasattr(pipeline, 'named_steps'):
        raise ValueError("El modelo debe ser un Pipeline de scikit-learn")

    regressor = pipeline.named_steps.get('regressor')
    if regressor is None:
        raise ValueError("El pipeline no contiene un paso 'regressor'")

    print(f"   Tipo de regresor: {type(regressor).__name__}")

    # ========================================
    # 2. Obtener coeficientes e intercept
    # ========================================
    if not hasattr(regressor, 'coef_') or not hasattr(regressor, 'intercept_'):
        raise ValueError(
            f"El modelo {type(regressor).__name__} no es un modelo lineal "
            "con coef_ e intercept_"
        )

    coef = regressor.coef_
    intercept = float(regressor.intercept_)

    print(f"\nüìä Coeficientes extra√≠dos:")
    print(f"   N√∫mero de features: {len(coef)}")
    print(f"   Intercept: {intercept:.6f}")

    # ========================================
    # 3. Reconstruir dataset para obtener features y estad√≠sticas
    # ========================================
    print("\nüìä Reconstruyendo dataset para extraer metadata...")

    # Cargar datos desde Supabase
    if load_data_from_supabase is None or build_ml_dataset is None:
        raise ImportError(
            "No se pudieron importar funciones de baseline_predictive_model.py.\n"
            "Aseg√∫rate de que el archivo existe en ml/"
        )

    df_raw = load_data_from_supabase(role_id=role_id)
    X, y = build_ml_dataset(df_raw)

    # Obtener nombres de features
    feature_names = list(X.columns)

    # Validar que el n√∫mero de features coincida
    if len(feature_names) != len(coef):
        raise ValueError(
            f"Mismatch en n√∫mero de features:\n"
            f"  Modelo: {len(coef)} coeficientes\n"
            f"  Dataset: {len(feature_names)} features\n"
            f"Puede que el modelo se haya entrenado con datos diferentes."
        )

    print(f"   ‚úÖ Features identificados: {len(feature_names)}")
    print(f"   Features: {feature_names[:5]}...")

    # ========================================
    # 4. Calcular estad√≠sticas del target
    # ========================================
    target_stats = {
        'min': float(y.min()),
        'max': float(y.max()),
        'mean': float(y.mean()),
        'std': float(y.std())
    }

    print(f"\nüìä Estad√≠sticas del target (outcome_value):")
    print(f"   Min:  {target_stats['min']:,.2f}")
    print(f"   Max:  {target_stats['max']:,.2f}")
    print(f"   Mean: {target_stats['mean']:,.2f}")
    print(f"   Std:  {target_stats['std']:,.2f}")

    # ========================================
    # 5. Cargar m√©tricas si existen
    # ========================================
    suffix = f"role_{role_id}" if role_id else "global"
    metrics_path = OUTPUT_DIR / f"baseline_metrics_{suffix}.json"

    metrics = None
    if metrics_path.exists():
        with open(metrics_path, 'r') as f:
            metrics_data = json.load(f)
            # Obtener m√©tricas del modelo correspondiente
            model_name = model_path.stem.replace(f"_{suffix}", "")
            if model_name in metrics_data.get('models', {}):
                metrics = metrics_data['models'][model_name]['test']
                print(f"\nüìä M√©tricas de evaluaci√≥n cargadas:")
                print(f"   MAE:  {metrics['mae']:.4f}")
                print(f"   RMSE: {metrics['rmse']:.4f}")
                print(f"   R¬≤:   {metrics['r2']:.4f}")

    # ========================================
    # 6. Construir configuraci√≥n JSON
    # ========================================
    config = {
        "model_type": type(regressor).__name__.lower(),
        "trained_at": datetime.now().isoformat(),
        "role_scope": role_id if role_id else "global",
        "version": "1.0.0",

        # Features con sus coeficientes
        "features": [
            {
                "name": feature_names[i],
                "coef": float(coef[i]),
                "abs_coef": float(abs(coef[i]))
            }
            for i in range(len(feature_names))
        ],

        # Intercept del modelo
        "intercept": intercept,

        # Estad√≠sticas del target para normalizaci√≥n
        "target_stats": target_stats,

        # Informaci√≥n de entrenamiento
        "train_info": {
            "n_samples": len(X),
            "n_features": len(feature_names),
            "metrics": metrics if metrics else {
                "mae": None,
                "rmse": None,
                "r2": None
            }
        },

        # Configuraci√≥n de scoring
        "scoring_config": {
            "min_observations_required": 3,
            "default_imputation_value": 0.0,
            "normalization_method": "min_max",
            "confidence_calculation": "sqrt_n_over_20"
        }
    }

    print("\n‚úÖ Configuraci√≥n construida exitosamente")

    return config


# ============================================================================
# 2. GUARDAR CONFIGURACI√ìN
# ============================================================================

def save_config(config: Dict, output_path: Path):
    """
    Guarda la configuraci√≥n del modelo en JSON.

    Args:
        config: Diccionario con la configuraci√≥n
        output_path: Path donde guardar el JSON
    """
    print("\n" + "="*80)
    print("GUARDANDO CONFIGURACI√ìN")
    print("="*80)

    # Crear directorio si no existe
    output_path.parent.mkdir(exist_ok=True)

    # Guardar JSON con formato legible
    with open(output_path, 'w') as f:
        json.dump(config, f, indent=2)

    print(f"‚úÖ Configuraci√≥n guardada en: {output_path}")
    print(f"   Tama√±o: {output_path.stat().st_size:,} bytes")

    # Mostrar preview
    print("\nüìÑ Preview de la configuraci√≥n:")
    print(f"   Model type: {config['model_type']}")
    print(f"   Role scope: {config['role_scope']}")
    print(f"   Features: {config['train_info']['n_features']}")
    print(f"   Intercept: {config['intercept']:.6f}")
    print(f"   R¬≤: {config['train_info']['metrics'].get('r2', 'N/A')}")

    # Mostrar top 5 features m√°s importantes
    features_sorted = sorted(
        config['features'],
        key=lambda x: x['abs_coef'],
        reverse=True
    )

    print("\nüîù Top 5 features m√°s importantes (por coeficiente absoluto):")
    for i, feat in enumerate(features_sorted[:5], 1):
        sign = "+" if feat['coef'] > 0 else ""
        print(f"   {i}. {feat['name']}: {sign}{feat['coef']:.4f}")


# ============================================================================
# 3. VALIDAR CONFIGURACI√ìN (OPCIONAL)
# ============================================================================

def validate_config(config: Dict):
    """
    Valida que la configuraci√≥n tenga todos los campos requeridos.

    Args:
        config: Diccionario de configuraci√≥n

    Raises:
        ValueError: Si falta alg√∫n campo cr√≠tico
    """
    required_fields = [
        'model_type',
        'trained_at',
        'role_scope',
        'features',
        'intercept',
        'target_stats',
        'train_info'
    ]

    missing = [field for field in required_fields if field not in config]
    if missing:
        raise ValueError(f"Campos faltantes en la configuraci√≥n: {missing}")

    # Validar que features tenga al menos una entrada
    if not config['features'] or len(config['features']) == 0:
        raise ValueError("La configuraci√≥n debe tener al menos una feature")

    # Validar que cada feature tenga name y coef
    for i, feat in enumerate(config['features']):
        if 'name' not in feat or 'coef' not in feat:
            raise ValueError(f"Feature {i} est√° malformada: {feat}")

    print("‚úÖ Configuraci√≥n validada correctamente")


# ============================================================================
# 4. FUNCI√ìN PRINCIPAL
# ============================================================================

def main():
    """
    Funci√≥n principal del script.
    """
    # ========================================
    # Parse argumentos CLI
    # ========================================
    parser = argparse.ArgumentParser(
        description='HRKey - Export Model Configuration to JSON',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos:
  # Exportar modelo global (Ridge)
  python ml/export_hrkey_model_config.py

  # Exportar modelo de un rol espec√≠fico
  python ml/export_hrkey_model_config.py --role_id abc123-def456-...

  # Exportar un modelo espec√≠fico
  python ml/export_hrkey_model_config.py --model_path ml/models/linear_regression_global.pkl
        """
    )

    parser.add_argument(
        '--model_path',
        type=str,
        default=None,
        help='Path al modelo .pkl (default: ml/models/ridge_global.pkl)'
    )

    parser.add_argument(
        '--role_id',
        type=str,
        default=None,
        help='UUID del rol (si se omite, usa modelo global)'
    )

    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='Path de salida del JSON (default: ml/output/hrkey_model_config_*.json)'
    )

    args = parser.parse_args()

    # ========================================
    # Determinar paths
    # ========================================
    # Path del modelo
    if args.model_path:
        model_path = Path(args.model_path)
    else:
        suffix = f"role_{args.role_id}" if args.role_id else "global"
        model_path = MODELS_DIR / f"ridge_{suffix}.pkl"

    # Path de salida
    if args.output:
        output_path = Path(args.output)
    else:
        suffix = f"role_{args.role_id}" if args.role_id else "global"
        output_path = OUTPUT_DIR / f"hrkey_model_config_{suffix}.json"

    # ========================================
    # Ejecutar exportaci√≥n
    # ========================================
    try:
        # Extraer configuraci√≥n
        config = load_model_and_extract_config(model_path, role_id=args.role_id)

        # Validar
        validate_config(config)

        # Guardar
        save_config(config, output_path)

        # ========================================
        # Resumen final
        # ========================================
        print("\n" + "="*80)
        print("‚úÖ EXPORTACI√ìN COMPLETADA EXITOSAMENTE")
        print("="*80)

        print("\nüì¶ Archivos generados:")
        print(f"   {output_path}")

        print("\nüéØ Pr√≥ximos pasos:")
        print("   1. El backend puede cargar este JSON para calcular scores")
        print("   2. Usa el endpoint POST /api/hrkey-score con:")
        print("      { \"subject_wallet\": \"0xABC\", \"role_id\": \"uuid\" }")
        print("   3. El score se calcular√° sin necesidad de Python en producci√≥n")

        print("\nüí° Ejemplo de uso en Node.js:")
        print("   const config = require('./ml/output/hrkey_model_config_global.json');")
        print("   const score = intercept + features.reduce((sum, f, i) => sum + f.coef * x[i], 0);")

    except FileNotFoundError as e:
        print(f"\n‚ùå ERROR: {e}")
        sys.exit(1)

    except Exception as e:
        print(f"\n‚ùå ERROR INESPERADO: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ============================================================================
# ENTRY POINT
# ============================================================================

if __name__ == "__main__":
    main()
